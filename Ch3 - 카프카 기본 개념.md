# Ch3 - 카프카 기본 개념

# 1. 카프카 브로커, 클러스터, 주키퍼

### 데이터 저장, 전송

메모리가 아닌 디스크, 즉 파일 시스템을 활용. But 페이지 캐시를 사용하여 입출력 속도를 높임. 때문에 힙 메모리 사이즈를 크게 설정할 필요가 없음. 

### 데이터 복제, 싱크

데이터 복제는 파티션 단위로 이루어짐. 복제의 최대 개수는 브로커의 개수만큼. 최소 1(복제 없음). 팔로워 파티션이 리더 파티션의 오프셋 확인 후 자신의 오프셋과 차이가 있으면 리더 파티션으로부터 데이터 가져와서 저장. 

리더 파티션 장애 발생시 팔로워가 리더의 지위 넘겨받아 역할 수행. 데이터 유실되어도 무관하고 데이터 처리 속도가 중요하다면 복제 수 1 or 2, 금융 데이터 등과 같이 유실이 일어나서는 안되는 데이터는 3.

### 컨트롤러

컨트롤러 - 다른 브로커들 상태 체크, 브로커가 클러스터에서 빠지는 경우 해당 브로커에 존재하는 리더 파티션 재분배

브로커 중 한 대가 컨트롤러 역할. 컨트롤러 브로커에 장애 생기면 다른 브로커가 컨트롤러 역할

### 데이터 삭제

토픽의 데이터 가져가더라도 삭제되지 않음. 컨슈머, 프로듀서가 삭제 요청 불가. 브로커만 삭제할 수 있다. 

로그 세그먼트(log segment) - 데이터 삭제가 이루어지는 파일 단위. 다수의 데이터가 들어있어 일반 DB처럼 특정 데이터 선별하여 삭제 불가능

데이터 쌓이는 동안 파일 시스템으로 열려있으며 설정값에 의해 닫히고 삭제됨

`log.segment.bytes, log.segment.ms` - 세그먼트 파일이 닫힘. 기본값 1GB. 너무 작으면 자주 여닫아서 부하 발생

`log.retention.bytes, log.retention.ms` - 세그먼트 파일이 삭제됨. 

`log.retention.check.interval.ms` - 닫힌 세그먼트 파일을 체크하는 간격

메시지 키 기준으로 오래된 데이터 압축하는 정책도 가능

### 컨슈머 오프셋 저장

컨슈머 그룹 - 토픽이 특정 파티션으로부터 데이터 가져가서 처리하고 파티션의 어느 레코드까지 가져갔는지 확인 위해 오프셋 커밋. __consumer_offsets 토픽에 저장. 이를 토대로 컨슈머 그룹은 다음 레코드를 가져가서 처리

### 코디네이터

코디네이터(coordinator) - 클러스터의 브로커 중 한 대가 역할 수행. 컨슈머 그룹의 상태 체크, 파티션을 컨슈머와 매칭되도록 분배

리밸런스(rebalance) - 컨슈머가 그룹에서 빠지면 매칭되지 않은 파티션을 정상 동작하는 컨슈머로 할당, 끊임없이 데이터 처리되도록

### 주키퍼

메타데이터 관리

znode - 주키퍼에서 사용하는 데이터 저장 단위. tree 구조로 계층 구조를 가짐.
기본으로 카프카는 root znode를 기준으로 데이터 저장하지만 2개 이상의 카프카 클러스터 구축 시 root가 아닌 한 단계 아래의 znode를 카프카 브로커 옵션으로 설정하여 각기 다른 znode에 동작

`bin/zookeeper-shell.sh [IP]:2181` 주키퍼에 접속

## 2. 토픽과 파티션

토픽 - 카프카에서 데이터 구분하기 위해 사용하는 단위. 1개 이상의 파티션 소유

파티션 - 카프카 병렬처리의 핵심. '레코드(record)'가 저장. 큐(queue)와 비슷한 구조. but 데이터 가져갔다고 삭제하진 않음. 별개로 관리. 다양한 목적 가진 여러 컨슈머 그룹들이 데이터 여러 번 가져갈 수 있음.

### 토픽 이름 제약 조건

- 빈 문자열 X
- . or .. 으로 생성 X
- 249자 미만
- 영어 대소문자, 0~9, . , _ , - 조합
- __consumer_offsets, __transaction_state 는 카프카 내부 로직 관리 목적. 이 이름으로 생성 X
- 이름에 . 와 _ 가 동시에 들어가면 안됨. 생성은 할 수 있지만 WARNING
- 이미 있는 토픽의 . ↔ _ 바꿨을 때 이미 있다면 생성 X

### 작명 방법

카멜케이스보단(CamelCase) 케밥케이스(kebab-case) 또는 스네이크(snake_case) 권장

## 3. 레코드

타임스탬프, 메시지 키, 메시지 값, 오프셋으로 구성. 프로듀서에서 브로커로 전송되면 오프셋과 타임스탬프가 지정되어 저장. 한번 적재된 레코드는 수정할 수 없고 유지 기간 또는 용량에 따라서만 삭제됨

타임스탬프 - 브로커 기준 유닉스 시간. 프로듀서가 임의의 값 설정 가능, 0.10.0.0 이상에만 존재.

메시지 키 - 메시지 값 순서대로 처리하거나 메시지 값의 종류 나타내기 위해 사용. 프로듀서가 토픽에 레코드 전송할 때 메시지 키의 해시값 토대로 파티션 지정 → 동일 메시지 키: 동일 파티션 
어느 파티션인지는 알 수 없고 파티션 개수 변경되면 메시지 키와 파티션 매칭이 달라짐

메시지 값 - 데이터. 메시지 키, 값은 직렬화되어 브로커로 전송, 컨슈머는 동일 형태로 역직렬화를 수행. ex) StringSerializer로 했다면 똑같이. 

오프셋 - 컨슈머가 데이터 가져갈 때 이용. 0 이상의 숫자. 직접 지정 X. 이전 전송된 레코드의 오프셋 + 1. 컨슈머 그룹으로 이루어진 카프카 컨슈머들이 파티션의 데이터를 어디까지 가져갔는지 명확히 지정.

## 4. 카프카 클라이언트

### 1. 프로듀서 API

프로듀서 애플리케이션은 리더 파티션을 가지고 있는 카프카 브로커와 직접 통신. 데이터를 직렬화(자바 또는 외부 시스템에서 사용 가능하도록 바이트 형태로 데이터 변환)하여 카프카 브로커로 보내기 때문에 자바의 모든 형태로 전송 가능. 기본형, 참조형 뿐만 아니라 동영상, 이미지 등과 같은 바이너리 데이터 포함.

**프로듀서 중요 개념**

- 브로커로 데이터 전송시 내부적으로 파티셔너, 배치 생성 단계를 거친다
- 필수 파라미터인 토픽과 메시지 값 뿐만 아니라 추가 파라미터 사용하여 오버로딩하여 파티션 번호, 타임스탬프, 메시지 키 등 내부 변수 설정 가능
- `send()` 메서드 호출하면 파티셔너에서 토픽의 어느 파티션으로 갈 것인지 정해짐. 파티셔너 설정 안하면 DefaultPartitioner로 설정되어 파티션 정해진다. 레코드는 데이터 전송 전에 어큐뮬레이터(accumulator)에 데이터를 버퍼로 쌓아놓고 발송. 배치로 묶어서 전송된다
- 프로듀서 API에선 UniformStickyPartitioner, RoundRobinPartitioner 제공. 지정하지 않으면 Uniform. 둘 다 메시키 키 있을 때는 키의 해시값과 파티션 매칭하여 데이터 전송. 키가 없을 땐 최대한 동일하게 분배하는 로직 들어있음.
- RoundRobin~ : 레코드 들어오는 대로 파티션 순회하며 전송 → 배치로 묶이는 빈도 적다
- UniformSticky~: 이전에 비해 많은 데이터가 배치로 묶여 전송 → 성능 향상. Accumulator에 데이터가 배치로 묶일 때까지 기다렸다가 묶인 데이터를 동일한 파티션에 전송
- Partitioner 인터페이스 제공: 상속받아 메시지 키 or 값에 따른 파티션 지정 로직 적용 가능. 이를 통해 파티션 지정된 데이터는 accumulator에 버퍼로 쌓이고 센더(sender)스레드는 쌓인 배치 데이터를 가져가 브로커로 전송
- 압축 옵션을 통해 브로커로 전송시 압축 방식 지정. 미지정 시 압축 X. 옵션들로 gzip, snappy, lz4, zstd. 압축할 때, 컨슈머가 압축 풀 때 리소스 사용

**프로듀서 주요 옵션**

필수 옵션 - 반드시 설정

- `bootstrap.servers` - 브로커의 호스트 이름:포트   2개 이상도 가능
- `key.serializer` - 메시지 키 직렬화하는 클래스
- `value.serializer` - 값 직렬화하는 클래스

선택 옵션 - 필수는 아니지만, 중요하지 않은 건 아님. 기본값 잘 알아야

- `acks` - 전송 성공 여부.
기본 1: 리더 파티션에 저장되면 성공으로 판단
0: 전송 즉시 성공으로 판단
-1 or all: 토픽의 `min.insync.replicas`개수에 해당하는 리더, 팔로워 파티션에 저장되면 성공으로 판단
- `buffer.memory` - 배치로 모으기 위해 설정할 버퍼 메모리양. 기본 32MB
- `retries` - 프로듀서가 브로커로부터 에러 받고 난 뒤 재전송 시도 횟수. 기본 2147483647
- `batch.size` - 배치로 전송할 레코드 최대 용량. 작으면 네트워크 부담, 크면 메모리 부담. 기본 16384
- `linger.ms` - 배치 전송 전까지 기다리는 최소 시간. 기본 0
- `partitioner.class` - 파티셔너 클래스 지정. 
기본 `org.apache.kafka.clients.producer.internals.DefaultPartitioner`
- `enable.idempotence` - 멱등성 프로듀서로 동작할지 여부. 기본 false
- `transactional.id` - 레코드를 트랜잭션 단위로 묶을지 여부. 프로듀서 고유 트랜잭션 아이디 설정 가능. 설정하면 트랜잭션 프로듀서로 동작. 기본 null

**메시지 키 포함된 프로듀서 - 파라미터: 토픽 이름, 키, 값**

`ProducerRecord<String, String> record = new ProducerRecord<>("test", "Pangyo","23")`

**파티션 포함**

`ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, partitionNo, messageKey, messageValue)`

**커스텀 파티셔너 생성 후 지정**

```java
Properties configs = new Properties();
configs.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, CustomerPartitioner.class);
KafkaProducer<String, String> producer = new KafkaProducer<>(configs);
```

**브로커 정상 전송 여부 확인**

```java
RecordMetadata metadata = producer.send(record).get();
logger.info(metadata.toString());
```

출력 `INFO com.example.ProducerWithSyncCallback - test-2@1`  ← 토픽-파티션@오프셋

비동기: Callback 상속하여 사용 `producer.send(record, new ProducerCallback());` → send 함수에서 레코드와 함께 Callback 클래스 넣으면 비동기로 결과 받음. But, 비동기라 순서 보장 X

### 2. 컨슈머 API

**컨슈머 중요 개념**

- 운영 방법 2가지
1) 1개 이상의 컨슈머로 이루어진 컨슈머 그룹 운영
  - 각 컨슈머 그룹이 격리, 안전하게 운영. 다른 역할을 하는 그룹이 영향 X → 각 컨슈머 쪽이 장애 발생하더라도 다른 쪽엔 ㄱㅊ
  - 1개의 파티션 최대 1개의 컨슈머에 할당, 1개 컨슈머는 여러 파티션 가능
    → 컨슈머 그룹의 컨슈머 개수 ≤ 토픽의 파티션 개수

    2) 토픽의 특정 파티션만 구독하는 컨슈머 운영

- 리밸런싱

리밸런싱- 컨슈머 추가, 제외되는 상황에서, 파티션의 소유권을 다른 컨슈머에 넘겨줌. 리밸런싱 중에는 컨슈머들이 토픽의 데이터 읽을 수 없음

그룹 조정자(group coordinator) - 리밸런싱 발동시키는 역할. 컨슈머 추가, 삭제 감지. 브로커 중 한 대가 그룹 조정자의 역할 수행

- 커밋 - 특정 토픽의 파티션을 어떤 컨슈머 그룹이 몇 번째 가져갔는지

카프카 브로커 내부의 __consumer_offsets에 기록. 데이터 처리 중복 발생하지 않게 하려면 컨슈머 애플리케이션이 오프셋 커밋을 정상적으로 처리했는지 검증.

비명시적으로 수행 - 기본으로 `poll()` 메서드 수행 시 `enable.auto.commit=true` 로 설정되어 일정 간격마다 오프셋 커밋. 코드 작성 필요 X. But, `poll()` 호출 이후 리밸런싱 또는 컨슈머 강제종료 시 처리하는 데이터 중복 또는 유실에 취약
`auto.commit.interval.ms` : 자동 커밋되는 간격

명시적 - `poll()` 호출 이후 반환된 데이터 처리 완료되고 `commitSync()` 호출

`commitSync()` - poll() 통해 반환된 레코드의 가장 마지막 오프셋 기준 커밋 수행. 커밋 요청하고 커밋 잘 처리됐는지 응답하기까지 기다림 → 컨슈머 처리량에 영향

`commitAsync()` - 커밋 요청 전송하고 응답 올 때까지 데이터 처리 수행 가능. But, 커밋 요청 실패할 경우 현재 처리중인 데이터 순서 보장 X, 중복 발생 가능

- 내부 구조

애플리케이션 실행 → 내부에서 Fetcher 인스턴스 생성, 레코드들을 미리 내부 큐로 가져옴 → `poll()` 호출하면 내부 큐에 있는 레코드 반환받아 처리 수행

**컨슈머 주요 옵션**

필수 옵션

- bootstrap.servers - 프로듀서와 동일
- key.deserializer - 키 역직렬화 클래스
- value.deserializer - 값 역직렬화 클래스

선택 옵션

- group.id - 컨슈머 그룹 아이디. `subscribe()` 로 토픽 구독할 떈 필수. 기본 null
- auto.offset.reset - 특정 파티션 읽을 때 저장된 컨슈머 오프셋 없는 경우 어느 오프셋부터 읽을지. 오프셋 있으면 이 옵션 무시. 기본 latest
latest: 가장 높은(최근) 오프셋부터
earliest: 가장 낮은(오래된) 오프셋부터
none: 커밋한 기록 찾아보고, 없으면 오류, 있으면 기존 기록 이후부터.
- enable.auto.commit - 자동 커밋 or 수동 커밋. 기본 true
- auto.commit.interval.ms - 자동 커밋일 경우 간격. 기본 5초
- max.poll.records - poll() 메서드 통해 반환되는 레코드 개수. 기본 500
- session.timeout.ms - 컨슈머와 브로커 연결 끊기는 최대 시간. 이 시간동안 heartbeat 전송 안하면 컨슈머 죽었다 생각하고 리밸런싱 시작. 보통 heartbeat 시간의 3배. 기본 10초
- heartbeat.interval.ms - 하트비트 시간 간격. 기본 3초(3000)
- max.poll.interval.ms - poll() 메서드 호출하는 간격의 최대 시간. 호출 이후 데이터 처리에 시간 너무 많이 걸리면 비정상으로 판단하고 리밸런싱 시작. 기본 5분(300000)
- isolation.level - 트랜잭션 프로듀서가 레코드를 트랜잭션 으로 보낼 때.기본 read_uncommitted
read_committed: 커밋 완료된 레코드만 읽음
read_uncommitted: 커밋 여부와 관계없이 파티션의 모든 레코드 읽음

### 3. 어드민 API

AdminClient 클래스 이용

```java
Properties configs = new Properties();
configs.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "IP:9092");
AdminClient admin = AdminClient.create(configs);
```